{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Using cached keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
      "Requirement already satisfied: packaging in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Using cached kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->keras-tuner) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->keras-tuner) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n",
      "Collecting scipy\n",
      "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/a3/d3/f88285098505c8e5d141678a24bb9620d902c683f11edc1eb9532b02624e/scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/saturncloud/envs/saturn/lib/python3.9/site-packages (from scipy) (1.21.6)\n",
      "Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner\n",
    "!pip install scipy\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "In the course instructor used this parameters:\n",
    "\n",
    "learning rate: [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "sizes of inner layer [10, 100, 1000],\n",
    "\n",
    "droprate = [0.0, 0.2, 0.5, 0.8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 14:04:54.264785: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Pre-trained convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3068 images belonging to 10 classes.\n",
      "Found 341 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/train',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = train_gen.flow_from_directory(\n",
    "    './clothing-dataset-small/validation',\n",
    "    target_size=(299, 299),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(hp):\n",
    "    c.clear_session()\n",
    "    base_model = Xception(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(299, 299, 3)\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    #########################################\n",
    "    inputs = keras.Input(shape=(299, 299, 3))\n",
    "    base = base_model(inputs, training=False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    # Size Inner Block\n",
    "    size_inner= hp.Choice(\"size_inner\", values = [10, 100, 1000])\n",
    "    inner = keras.layers.Dense(size_inner, activation='relu')(vectors)\n",
    "    \n",
    "    #Droprate Block\n",
    "    droprate = hp.Choice(\"droprate\", values= [0.0, 0.2, 0.5, 0.8]) # As an alternaive droprate = hp.Int(\"droprate\", min_value=0.0, max_value=0.8, step=0.2)\n",
    "    drop = keras.layers.Dropout(droprate)(inner)\n",
    "\n",
    "\n",
    "    \n",
    "    outputs = keras.layers.Dense(10)(drop)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "    # Learning Rate Block\n",
    "    learning_rate = hp.Choice(\"learning_rate\", values=[0.0001, 0.001, 0.01, 0.1])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=\"/home/jovyan/workspace/logs/fit\"\n",
    "callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=0,\n",
    "write_graph=True,\n",
    "write_images=False,\n",
    "write_steps_per_second=False,\n",
    "update_freq='epoch',\n",
    "profile_batch=0,\n",
    "embeddings_freq=0,\n",
    "embeddings_metadata=None,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuner RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 14:05:00.850037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:00.856826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:00.857089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:00.857661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-03 14:05:00.858063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:00.858365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:00.858576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:01.628342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:01.628623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:01.628822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-09-03 14:05:01.628996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13794 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "size_inner (Choice)\n",
      "{'default': 10, 'conditions': [], 'values': [10, 100, 1000], 'ordered': True}\n",
      "droprate (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.2, 0.5, 0.8], 'ordered': True}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.0001, 'conditions': [], 'values': [0.0001, 0.001, 0.01, 0.1], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    make_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=25,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir1') #change the directory name here  when rerunning the cell else it gives \"Oracle exit error\" \n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 22m 56s]\n",
      "val_accuracy: 0.8856304883956909\n",
      "\n",
      "Best val_accuracy So Far: 0.900293231010437\n",
      "Total elapsed time: 07h 35m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_ds, epochs=20, validation_data=val_ds,\n",
    "                   callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir1/untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "size_inner: 100\n",
      "droprate: 0.5\n",
      "learning_rate: 0.001\n",
      "Score: 0.900293231010437\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "size_inner: 1000\n",
      "droprate: 0.8\n",
      "learning_rate: 0.001\n",
      "Score: 0.8914955854415894\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "size_inner: 100\n",
      "droprate: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.8885630369186401\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "size_inner: 100\n",
      "droprate: 0.2\n",
      "learning_rate: 0.01\n",
      "Score: 0.8856304883956909\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "size_inner: 100\n",
      "droprate: 0.8\n",
      "learning_rate: 0.001\n",
      "Score: 0.8856304883956909\n",
      "\n",
      "Trial 19 summary\n",
      "Hyperparameters:\n",
      "size_inner: 1000\n",
      "droprate: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.8856304883956909\n",
      "\n",
      "Trial 10 summary\n",
      "Hyperparameters:\n",
      "size_inner: 1000\n",
      "droprate: 0.2\n",
      "learning_rate: 0.01\n",
      "Score: 0.873900294303894\n",
      "\n",
      "Trial 13 summary\n",
      "Hyperparameters:\n",
      "size_inner: 1000\n",
      "droprate: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.873900294303894\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "size_inner: 100\n",
      "droprate: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.8563050031661987\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "size_inner: 10\n",
      "droprate: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.8533724546432495\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size_inner': 100, 'droprate': 0.5, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "best_params = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_params.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop =tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=17,\n",
    "    verbose=0,\n",
    "    mode='max',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.hypermodel.build(best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 69s 714ms/step - loss: 0.5385 - accuracy: 0.8256 - val_loss: 0.4309 - val_accuracy: 0.8739\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 69s 720ms/step - loss: 0.4788 - accuracy: 0.8357 - val_loss: 0.4289 - val_accuracy: 0.8739\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 69s 721ms/step - loss: 0.4271 - accuracy: 0.8559 - val_loss: 0.3897 - val_accuracy: 0.8680\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 68s 706ms/step - loss: 0.3934 - accuracy: 0.8677 - val_loss: 0.3607 - val_accuracy: 0.8739\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 69s 720ms/step - loss: 0.3801 - accuracy: 0.8693 - val_loss: 0.3821 - val_accuracy: 0.8563\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 68s 706ms/step - loss: 0.3445 - accuracy: 0.8833 - val_loss: 0.3553 - val_accuracy: 0.8827\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 68s 707ms/step - loss: 0.3252 - accuracy: 0.8862 - val_loss: 0.3716 - val_accuracy: 0.8739\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 69s 713ms/step - loss: 0.3244 - accuracy: 0.8882 - val_loss: 0.3490 - val_accuracy: 0.8592\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 69s 714ms/step - loss: 0.3101 - accuracy: 0.8970 - val_loss: 0.3719 - val_accuracy: 0.8856\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 68s 707ms/step - loss: 0.2966 - accuracy: 0.8957 - val_loss: 0.3871 - val_accuracy: 0.8710\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 69s 714ms/step - loss: 0.2702 - accuracy: 0.9009 - val_loss: 0.3968 - val_accuracy: 0.8534\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 68s 712ms/step - loss: 0.2652 - accuracy: 0.9081 - val_loss: 0.4021 - val_accuracy: 0.8710\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 72s 751ms/step - loss: 0.2429 - accuracy: 0.9156 - val_loss: 0.3675 - val_accuracy: 0.8827\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 68s 710ms/step - loss: 0.2355 - accuracy: 0.9192 - val_loss: 0.3537 - val_accuracy: 0.8768\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 69s 717ms/step - loss: 0.2400 - accuracy: 0.9133 - val_loss: 0.3806 - val_accuracy: 0.8739\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 68s 709ms/step - loss: 0.2401 - accuracy: 0.9198 - val_loss: 0.3826 - val_accuracy: 0.8710\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(train_ds, epochs=50, validation_data=val_ds,\n",
    "                   callbacks=[callback, early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
